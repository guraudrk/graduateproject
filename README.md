1.프로젝트의 이름

이름:ai 세종대왕

2.프로젝트 요약 설명(설명/기간/같이한 사람들 수/맡았던 역활)

설명:세종대왕에 대한 정보를 수집하기 위해 pyhton의 웹 크롤링, 한글 형태소 분석 등을 통해 데이터를 전처리하고 그 데이터를 lstm 등의 딥러닝,머신러닝 알고리즘을 통해 챗봇을 만든다. 

이 챗봇을 평가하고 튜닝하는 과정을 거쳐 실제 세종대왕과 이야기하는 것 같은 챗봇 모델을 만든다. 

그런 다음, streamlit cloud를 통해 챗봇을 웹 사이트에서 사용할 수 있게 해서 웹 서비스를 만든다.(저장소:streamlit-chat)


기간:2024년 3월~(진행중)

같이한 사람들 수:1명(개인프로젝트)

맡았던 역활:프로젝트 총괄




3.사용한 기술 스텍

코드 툴: vscode(프론트,백엔드,flask)/jupyter notebook(딥러닝,크롤링,머신 학습) 

프론트엔드:react 

백엔드:springboot,java/데이터베이스, 배포:aws(데이터베이스:RDS/배포:EC2) 

딥러닝:파이썬(RNN/LSTM)/딥러닝과 백엔드 연결:FLASK/디자인:figma

챗봇 배포:streamlit cloud




4.구현 기술(어떤 기술을 사용하여 어떤 것을 구현했는지)

springboot와 react의 연동: 이전 프로젝트들에서 node.js와 react를 한 프로젝트에 사용하고, springboot와 thymeleaf를 한 프로젝트에 사용한 적은 있었지만 

springboot와 react의 연동을 한 적은 처음이었다.

여러 시행착오가 있었으나(맡의 '시행착오' 란에서 자세히 언급) 연동을 성공적으로 마쳐 기술력을 향상시킬 수 있었다.

mvc 패턴 활용:mvc 패턴은 디자인 패턴의 일종으로, Model-View-Controller의 약자이다. 

이 패턴은 어플리케이션을 세 가지 주요 구성 요소로 분리하여 코드의 유지보수성을 높히고, 역활을 명확하게 해서 복잡성을 줄이는 데에 목적을 가진다. 

아키텍쳐로는 레이어드 아키텍쳐가 이와 비슷하다고 볼 수 있다.

jpa: java Persistence API의 약자로, 자바 애플리케이션에서 관계형 데이터베이스를 사용하는 데 필요한 데이터 접근 계층을 쉽게 작성할 수 있게 도와주는 자바 표준 API이다. 

이를 통해 개발자는 SQL을 직접 작성하지 않고도 데이터베이스 작업을 수행할 수 있다.


딥러닝을 통한 챗봇 구성: 웹 크롤링,LSTM,한글 전처리, 후처리, QA 배열과 코사인 유사도를 활용한 챗봇을 구성하였다.(저장소 이름:aikingsejong-python)


아키택쳐들을 활용한 회원가입/로그인/게시판 구성:앞서 이야기한 mvc 패턴/spa 아키텍쳐와 레이어드 아키텍쳐를 활용하에 회원가입/로그인/게시판 구성의 기능들을 비교적 쉽고 빠르게 구축하는 데에 성공하였다.

아키텍쳐와 mvc 패턴에 대한 공부가 없었다면 절대로 쉽게 완성시키지 못했고, 아예 완성시키지 못했을 것이다.




5.시행착오(유의미한 경험/얻은 인사이트,겪은 오류,해결 방법,갈등 및 해결)


springboot와 react의 연동:예전의 프로젝트들은 같은 개발 시스템 하에 있었기 때문에 연동하는 데에 특별히 큰 힘이 들어가지 않았으나, 

이번 프로젝트는 SPA(Single Page Application)를 이용해서 하는 첫 프로젝트여서 초반에 많은 오류에 직면했고, 사소한 오류(앤드포인트 설정)로 1주일 이상 시간을 날렸던 적도 있었다. 

대표적인 오류는 프론트와 백엔드에 프록시를 설정해 주는 것이었다. 필자는 프론트와 백엔드에 프록시 설정을 해 줘야 한다는 것도 몰라 엄한 시간을 잡아먹었었는데, setUpProxy 파일과 Config 파일에서 각자 프록시 설정을 해 줌으로서 문제를 해결했다. 

오류를 해결하고 백엔드의 공부를 꾸준히 한 결과 spa에서 api 설계 및 구현 능력/데이터베이스 설계 및 최적화/springboot 및 jpa 사용 경험/aws 사용 능력 등을 갖출 수 있었다.


챗봇 구성의 시행착오: 인공지능을 활용하여 프로젝트를 한 적은 많았으나, 챗봇을 구성하는 것은 처음이었기에 웹 크롤링 부분부터 엄청나게 많은 시행착오를 겪었어야 했다.

시행착오 중에서 가장 골칫거리였던 것은 바로 LSTM이 웹 크롤링을 한 내용을 바탕으로 학습을 하는데, 학습 결과가 매우 좋지 않아 문장은 겨녕 '은 은 은 은 은'과 같은 출력값이 나왔다는 것이다.

이 문제는 QA배열을 정의하고, 그 배열을 중심으로 모델 학습을 하라고 지시를 하니 해결이 되었다.

두번째 문제는 모델의 정확도 문제였다. lstm으로 학습을 하는데, 정확도가 36프로 남짓하는 문제가 생겼다.

이를 해결하기 위해 여러 parameter를 조작하면서 해결책을 모색했고, layer의 수를 늘림으로서 90프로 이상의 모델 정확도를 가질 수 있게 되었다.





6.참고 사진
